"""
RoboInter LMDB Reader and Validation Script

Reads and validates LMDB files generated by convert_pkl_to_lmdb.py.

LMDB data format (each key corresponds to a video):
{
    0: {  # frame_id
        'time_clip': [[0,132],[132,197],[198,224]] or None,
        'instruction_add': str or None,
        'substask': str or None,
        'primitive_skill': str or None,
        'segmentation': None,
        'object_box': [[x1,y1],[x2,y2]] or None,
        'placement_proposal': [[x1,y1],[x2,y2]] or None,
        'trace': [[x,y], ...] or None,
        'gripper_box': [[x1,y1],[x2,y2]] or None,
        'contact_frame': int or -1 or None,
        'state_affordance': [6 floats] or [] or None,
        'affordance_box': [[x1,y1],[x2,y2]] or [] or None,
        'contact_points': [x, y] or [] or None,
    },
    1: {...},
    ...
}

Usage:
    python read_lmdb.py --action info
    python read_lmdb.py --action keys --limit 20
    python read_lmdb.py --action item --key <video_id> --sample_frame 0
    python read_lmdb.py --action stats --key <video_id>
    python read_lmdb.py --action summary --limit 100
"""

import lmdb
import pickle
import argparse


# All per-frame fields in the LMDB
ALL_FIELDS = [
    'time_clip', 'instruction_add', 'substask', 'primitive_skill',
    'segmentation', 'object_box', 'placement_proposal', 'trace',
    'gripper_box', 'contact_frame', 'state_affordance',
    'affordance_box', 'contact_points'
]


def open_lmdb(lmdb_path):
    """Open LMDB in readonly mode, compatible with network filesystems."""
    return lmdb.open(
        lmdb_path,
        readonly=True,
        lock=False,
        readahead=False,  # Must be disabled for network filesystems
        max_readers=126,
    )


def read_lmdb_keys(lmdb_path, limit=None):
    """Read all keys from the LMDB."""
    env = open_lmdb(lmdb_path)
    keys = []
    with env.begin() as txn:
        cursor = txn.cursor()
        for key, _ in cursor:
            key_str = key.decode("utf-8")
            keys.append(key_str)
            if limit and len(keys) >= limit:
                break
    env.close()
    return keys


def read_lmdb_item(lmdb_path, key):
    """Read a single item from the LMDB."""
    env = open_lmdb(lmdb_path)
    data = None
    with env.begin() as txn:
        value = txn.get(key.encode("utf-8"))
        if value:
            data = pickle.loads(value)
    env.close()  # Must be closed outside the with block
    return data


def get_lmdb_info(lmdb_path):
    """Get basic LMDB information."""
    env = open_lmdb(lmdb_path)
    with env.begin() as txn:
        stat = env.stat()
        total_entries = stat['entries']

    # Count DROID and RH20T entries
    droid_count = 0
    rh20t_count = 0
    sample_keys = []
    with env.begin() as txn:
        cursor = txn.cursor()
        for key, _ in cursor:
            key_str = key.decode("utf-8")
            if key_str.startswith("RH20T"):
                rh20t_count += 1
            else:
                droid_count += 1
            if len(sample_keys) < 5:
                sample_keys.append(key_str)
    env.close()

    return {
        'total_entries': total_entries,
        'droid_count': droid_count,
        'rh20t_count': rh20t_count,
        'sample_keys': sample_keys,
    }


def print_item_structure(data, sample_frame=0):
    """Print the structure of a single item."""
    if data is None:
        print("Data is None")
        return

    print("\n" + "=" * 60)
    print("Item Structure:")
    print("=" * 60)

    # Get all frame IDs
    frame_ids = sorted([k for k in data.keys() if isinstance(k, int)])

    print(f"Total frames: {len(frame_ids)}")
    print(f"Frame range: {min(frame_ids) if frame_ids else 'N/A'} - {max(frame_ids) if frame_ids else 'N/A'}")

    # Get time_clip and instruction from frame 0 (same across all frames)
    if frame_ids:
        first_frame = data[frame_ids[0]]
        tc = first_frame.get('time_clip')
        inst = first_frame.get('instruction_add')
        print(f"time_clip: {tc}")
        print(f"instruction: {inst}")

    # Print sample frame
    if sample_frame in data:
        print(f"\nSample frame {sample_frame}:")
        print("-" * 40)
        frame_data = data[sample_frame]
        for k, v in frame_data.items():
            if v is None:
                print(f"  {k}: None")
            elif isinstance(v, list) and len(v) > 3:
                print(f"  {k}: list[{len(v)}] first 3: {v[:3]}")
            elif isinstance(v, str) and len(v) > 80:
                print(f"  {k}: {v[:80]}...")
            else:
                print(f"  {k}: {v}")
    else:
        print(f"\nFrame {sample_frame} not found (valid range: {min(frame_ids)}-{max(frame_ids)})")


def count_valid_fields(data):
    """
    Count the number of frames with valid data for each field.

    Distinguishes three states:
    - valid: has actual data
    - None: data source does not exist
    - []/−1: temporal reason (e.g., past the contact frame)
    """
    if data is None:
        return {}

    frame_ids = sorted([k for k in data.keys() if isinstance(k, int)])

    # Fields to count (excluding global/unused fields: time_clip, instruction_add, segmentation)
    fields = [
        'substask', 'primitive_skill',
        'object_box', 'placement_proposal', 'trace',
        'gripper_box', 'contact_frame',
        'state_affordance', 'affordance_box', 'contact_points'
    ]

    counts_valid = {f: 0 for f in fields}
    counts_none = {f: 0 for f in fields}
    counts_empty = {f: 0 for f in fields}  # [] or -1

    for frame_id in frame_ids:
        frame_data = data.get(frame_id, {})
        for f in fields:
            v = frame_data.get(f)
            if v is None:
                counts_none[f] += 1
            elif v == [] or v == -1 or v == '':
                counts_empty[f] += 1
            else:
                counts_valid[f] += 1

    total = len(frame_ids)
    print("\n" + "=" * 60)
    print("Field Coverage Statistics:")
    print(f"Total frames: {total}")
    print("=" * 60)
    print(f"  {'field':<22s} {'valid':>8s} {'None':>8s} {'[]/−1':>8s}")
    print("-" * 60)
    for f in fields:
        v = counts_valid[f]
        n = counts_none[f]
        e = counts_empty[f]
        v_pct = (v / total * 100) if total > 0 else 0
        print(f"  {f:<22s} {v:>5d} ({v_pct:5.1f}%) {n:>5d}    {e:>5d}")

    return counts_valid


def summarize_items(lmdb_path, limit=100):
    """
    Scan multiple items and produce aggregate statistics.

    Reports:
    - Field coverage across all items (percentage of items with at least one valid frame)
    - Average frame count
    - Number of items with language annotations
    """
    env = open_lmdb(lmdb_path)

    fields = [
        'substask', 'primitive_skill',
        'object_box', 'placement_proposal', 'trace',
        'gripper_box', 'contact_frame',
        'state_affordance', 'affordance_box', 'contact_points'
    ]

    item_has_field = {f: 0 for f in fields}
    item_has_language = 0
    total_frames_list = []
    item_count = 0

    with env.begin() as txn:
        cursor = txn.cursor()
        for key_bytes, value_bytes in cursor:
            if limit and item_count >= limit:
                break
            data = pickle.loads(value_bytes)
            frame_ids = [k for k in data.keys() if isinstance(k, int)]
            total_frames_list.append(len(frame_ids))

            # Check whether language annotation exists
            if frame_ids:
                first_frame = data[frame_ids[0]]
                if first_frame.get('instruction_add') is not None:
                    item_has_language += 1

            # Check whether each field has at least one valid frame
            for f in fields:
                for fid in frame_ids:
                    v = data[fid].get(f)
                    if v is not None and v != [] and v != -1 and v != '':
                        item_has_field[f] += 1
                        break

            item_count += 1

    env.close()

    print("\n" + "=" * 60)
    print(f"Summary (scanned {item_count} items):")
    print("=" * 60)
    avg_frames = sum(total_frames_list) / len(total_frames_list) if total_frames_list else 0
    print(f"  Average frames per item: {avg_frames:.1f}")
    print(f"  Min frames: {min(total_frames_list) if total_frames_list else 'N/A'}")
    print(f"  Max frames: {max(total_frames_list) if total_frames_list else 'N/A'}")
    print(f"  Items with language: {item_has_language}/{item_count} ({item_has_language/item_count*100:.1f}%)")
    print()
    print(f"  Field coverage (items with at least 1 valid frame):")
    print("-" * 60)
    for f in fields:
        c = item_has_field[f]
        pct = (c / item_count * 100) if item_count > 0 else 0
        print(f"    {f:<22s}: {c:>5d}/{item_count} ({pct:5.1f}%)")

    return item_has_field


def main():
    parser = argparse.ArgumentParser(description="Read and validate RoboInter LMDB")
    parser.add_argument(
        "--lmdb_path",
        type=str,
        default="",
        help="Path to the LMDB directory"
    )
    parser.add_argument(
        "--action",
        type=str,
        choices=["info", "keys", "item", "stats", "summary"],
        default="info",
        help="Action: info=basic info, keys=list keys, item=show single item, stats=per-item field stats, summary=multi-item aggregate"
    )
    parser.add_argument(
        "--key",
        type=str,
        default=None,
        help="Key to read (for item and stats actions; defaults to first key if not specified)"
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=10,
        help="Limit for keys display / summary scan count"
    )
    parser.add_argument(
        "--sample_frame",
        type=int,
        default=0,
        help="Frame ID to display"
    )

    args = parser.parse_args()

    if args.action == "info":
        print("\n" + "=" * 60)
        print("LMDB Info:")
        print("=" * 60)
        info = get_lmdb_info(args.lmdb_path)
        print(f"  Total items: {info['total_entries']}")
        print(f"  DROID items: {info['droid_count']}")
        print(f"  RH20T items: {info['rh20t_count']}")
        print(f"\n  Sample keys (first {len(info['sample_keys'])}):")
        for k in info['sample_keys']:
            print(f"    - {k}")

    elif args.action == "keys":
        print(f"\nFirst {args.limit} keys:")
        print("-" * 40)
        keys = read_lmdb_keys(args.lmdb_path, limit=args.limit)
        for k in keys:
            print(f"  {k}")
        print(f"\n  Total shown: {len(keys)}")

    elif args.action == "item":
        if args.key is None:
            keys = read_lmdb_keys(args.lmdb_path, limit=1)
            if keys:
                args.key = keys[0]
                print(f"Using first key: {args.key}")
            else:
                print("No keys found in LMDB")
                return

        print(f"\nReading item: {args.key}")
        data = read_lmdb_item(args.lmdb_path, args.key)
        print_item_structure(data, args.sample_frame)

    elif args.action == "stats":
        if args.key is None:
            keys = read_lmdb_keys(args.lmdb_path, limit=1)
            if keys:
                args.key = keys[0]
                print(f"Using first key: {args.key}")
            else:
                print("No keys found in LMDB")
                return

        print(f"\nStatistics for item: {args.key}")
        data = read_lmdb_item(args.lmdb_path, args.key)
        print_item_structure(data, args.sample_frame)
        count_valid_fields(data)

    elif args.action == "summary":
        summarize_items(args.lmdb_path, limit=args.limit)


if __name__ == "__main__":
    main()
